# diary-ai

<p align="center">
  <img src="./images/wizard_diary.png" width="200" alt="Blobby Logo" />
</p>

diary-ai processes, embed and stores diary entries in Qdrant vector database.

Its an implementation of the [Retrieval-augmented generation](https://en.wikipedia.org/wiki/Retrieval-augmented_generation) architecture

The `prompt.py` allows for prompting the diary data.

You can embed and prompt the data using `openai`, `gemini` or `ollama`

## Prerequisites

#### Dependencies
* [Python 3.11+](https://www.python.org/downloads/)
* [Poetry](https://python-poetry.org/docs/#installation)

#### External Services
* Create a [Qdrant Account](https://qdrant.tech/) a free one will do

#### Open AI
* Create an [Open API Secret Key](https://platform.openai.com/api-keys)
* Update the `TEXT_EMBEDDING_PRODUCT` and `GENERATION_LLM`

> It does not cost much to process and test but openai requires at least 5$ deposited

#### Gemini
* You will need a [GCP account](https://cloud.google.com/cloud-console)
* Enable [Gemini API](https://ai.google.dev/) in google cloud console
* Enable [Vertex AI](https://cloud.google.com/vertex-ai) in google cloud console
* You will need [gcloud cli](https://cloud.google.com/sdk/docs/install)
  * You will need to `glcoud init`
  * And `gcloud auth application-default login`
* You will also need to enable billing
* Update the `TEXT_EMBEDDING_PRODUCT` and `GENERATION_LLM`

#### Ollama Models
This is an option to run this project locally
* Install Ollama
  * `brew install ollama` for macOS
  * `ollama serve`
  * `ollama pull llama3`
* Update the `TEXT_EMBEDDING_PRODUCT` and `GENERATION_LLM`

## Usage

After installation, you can use diary-ai by running the following

```shell
  python prompt.py
```
## Before installation

> ![Message](https://img.shields.io/badge/TEXT_EMBEDDING_PRODUCT-EMBEDDING-green)
> 
> `TEXT_EMBEDDING_PRODUCT` env var effects the `embedding` of the data and the qdrant collection size
> 
> Set this variable to one of its options and run the setup.py. It's a one-to-one relationship with the collection

> ![Message](https://img.shields.io/badge/GENERATION__API-LLM-green) 
> 
>`GENERATION_LLM` env var is for deciding which api to send your prompt to 
> 
> So you can embed your data with openai but generate a response from gemini

Create two different collections and run setup twice to store the diaries with different embeddings
if you want to play around


## Installation

```shell
  poetry install
```

Create a `.env` file and add the following to it

```dotenv
QDRANT_URL=qdrant_endpoint # you can find it in the cluster
QDRANT_API_KEY=api_key
QDRANT_COLLECTION=collection_name # defaults to diaries
OPEN_AI_API_KEY=api_key
OPEN_AI_EMBEDDING_MODEL=text-embedding-ada-002 # default text-embedding-ada-002
GEMINI_API_KEY=api_key
GEMINI_EMBEDDING_MODEL=gemini-embedding-001 # default gemini-embedding-001
TEXT_EMBEDDING_PRODUCT=openai # options are openai or gemini
GENERATION_LLM=openai # options are openai or gemini
VERBOSE=false # defaults to false
OLLAMA_EMBEDDING_MODEL=all-mpnet-base-v2 # default all-mpnet-base-v2
GOOGLE_CLOUD_PROJECT_ID=project_id
```

Run the following script

```shell
  python setup.py
```

> Note: the method [store_diary_entry](qdrant_utils/qdrant_repository.py) will not allow duplication of samples

## Reset Qdrant Data
You can use the following script to delete all qdrant data in your `QDRANT_COLLECTION`

```shell
  python qdrant_utils/delete_collection_data.py
```

## The diary_samples

### freya and marc
Those samples where generated by chatGPT and are fictional characters

### dee
This is the diary of [John Dee](https://www.gutenberg.org/ebooks/19553)

### yone
This is Yon√© Noguchi [The American Diary Of a Japanese Girl](https://www.gutenberg.org/ebooks/63256)

### pepys
This is the diary of [Samuel Pepys](https://www.gutenberg.org/ebooks/4200)
